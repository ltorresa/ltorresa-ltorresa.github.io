<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="Generator" content="iWeb 3.0.4" />
    <meta name="iWeb-Build" content="local-build-20201003" />
    <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7" />
    <meta name="viewport" content="width=700" />
    <title>home</title>
    <link rel="stylesheet" type="text/css" media="screen,print" href="home_files/home.css" />
    <!--[if lt IE 8]><link rel='stylesheet' type='text/css' media='screen,print' href='home_files/homeIE.css'/><![endif]-->
    <!--[if gte IE 8]><link rel='stylesheet' type='text/css' media='screen,print' href='Media/IE8.css'/><![endif]-->
    <script type="text/javascript" src="Scripts/iWebSite.js"></script>
    <script type="text/javascript" src="Scripts/Widgets/SharedResources/WidgetCommon.js"></script>
    <script type="text/javascript" src="Scripts/Widgets/Navbar/navbar.js"></script>
    <script type="text/javascript" src="Scripts/iWebImage.js"></script>
    <script type="text/javascript" src="home_files/home.js"></script>
  </head>
  <body style="background: rgb(255, 255, 255); margin: 0pt; " onload="onPageLoad();" onunload="onPageUnload();">
    <div style="text-align: center; ">
      <div style="margin-bottom: 10px; margin-left: auto; margin-right: auto; margin-top: 10px; overflow: hidden; position: relative; word-wrap: break-word;  background: rgb(255, 255, 255); text-align: left; width: 700px; " id="body_content">
        <div style="margin-left: 0px; position: relative; width: 700px; z-index: 0; " id="nav_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
          <div class="com-apple-iweb-widget-navbar flowDefining" id="widget0" style="margin-left: 20px; margin-top: 0px; opacity: 1.00; position: relative; width: 680px; z-index: 1; ">
    
            <div id="widget0-navbar" class="navbar">

      
              <div id="widget0-bg" class="navbar-bg">

        
                <ul id="widget0-navbar-list" class="navbar-list">
 <li></li> 
</ul>
                
      
</div>
              
    
</div>
          </div>
          <script type="text/javascript"><!--//--><![CDATA[//><!--
new NavBar('widget0', 'Scripts/Widgets/Navbar', 'Scripts/Widgets/SharedResources', '.', {"path-to-root": "", "navbar-css": ".navbar {\n\tfont-family: 'Helvetica Neue', Arial, sans-serif;\n\tfont-size: .8em;\n\tcolor: #666666;\n\tline-height: 30px;\n\tborder-bottom: 3px solid #ccc;\n}\n\n.navbar-bg {\n\ttext-align: right;}\n\n.navbar-bg ul {\n\tlist-style: none;\n\tmargin: 0px;\n\tpadding: 0px;\n}\n\n\nli {\n\tlist-style-type: none;\n\tdisplay: inline;\n\tpadding: 0px 5px 0px 0px;\n}\n\n\nli a {\n\ttext-decoration: none;\n\tpadding: 10px;\n\tcolor: #666666;\n\tfont-weight: bold;\n}\n\nli a:visited {\n\ttext-decoration: none;\n\tpadding: 10px;\n\tcolor: #666666;\n\tfont-weight: bold;\n}\n\nli a:hover\r{\r\n \tcolor: #999999;\n\ttext-decoration: none;\r}\n\n\nli.current-page a\r{\r\t color: #66ABC5;\n\ttext-decoration: none;\r}", "current-page-GUID": "53243ACB-6697-4184-B8D3-F5B11E08E9D2", "isCollectionPage": "NO"});
//--><!]]></script>
          <div style="clear: both; height: 0px; line-height: 0px; " class="spacer"> </div>
        </div>
        <div style="height: 75px; margin-left: 0px; position: relative; width: 700px; z-index: 10; " id="header_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
        </div>
        <div style="margin-left: 0px; position: relative; width: 700px; z-index: 5; " id="body_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
          <div style="height: 281px; width: 251px;  height: 281px; left: 34px; position: absolute; top: 22px; width: 251px; z-index: 1; " class="tinyText style_SkipStroke stroke_0">
            <img src="home_files/LT.jpg" alt="" style="border: none; height: 281px; width: 251px; " />
          </div>
          


          <div id="id1" style="height: 2476px; left: 41px; position: absolute; top: 342px; width: 613px; z-index: 1; " class="style_SkipStroke_1 shape-with-text">
            <div class="text-content style_External_613_2476" style="padding: 0px; ">
              <div class="style">
                <p style="padding-top: 0pt; " class="paragraph_style">recent news<br /></p>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Two papers to be presented at NeurIPS 2020:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><span class="style_1">Spotlight presentation</span>:<br /><a title="https://arxiv.org/abs/1911.12667" href="https://arxiv.org/abs/1911.12667">Self-Supervised Learning by Cross-Modal Audio-Video Clustering</a>, <br />with Humam Alwassel, Dhruv Mahajan, Bernard Ghanem, and Du Tran.  <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2007.07306" href="https://arxiv.org/abs/2007.07306">COBE: Contextualized Object Embeddings from Narrated Instructional Video</a>, <br />with Gedas Bertasius.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>New paper to be presented at WACV 2021:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1907.08340" href="https://arxiv.org/abs/1907.08340">Only Time Can Tell: Discovering Temporal Data for Temporal Modeling</a>, <br />with Laura Sevilla-Lara, Shengxin Zha, Zhicheng Yan, Vedanuj Goswami, and Matt Feiszli.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>New paper to be presented at BMVC 2020:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1904.05410" href="https://arxiv.org/abs/1904.05410">Attentive Action and Context Factorization</a>, <br />with Yang Wang, Vinh Tran, Gedas Bertasius, and Minh Hoai.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span><span class="style_2">MaskProp</span> nominated for CVPR 2020 paper award and ranked first in one of the EPIC-Kitchens CVPR 2020 challenges:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/1912.04573" href="https://arxiv.org/abs/1912.04573">Classifying, Segmenting, and Tracking Object Instances in Video with Mask Propagation</a>, by Gedas Bertasius and Lorenzo Torresani, was one of the 29 paper award nominees at CVPR 2020 (out of 1470 accepted papers). <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span>Our software submission based on this paper received the First Place Award on Unseen Kitchens and the Third Place Award on Seen Kitchens at the IEEE CVPR 2020 EPIC-Kitchens Object Detection in Video Challenge.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Three papers presented at CVPR 2020:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><span class="style_1">Oral presentation</span>:<br /><a title="https://arxiv.org/abs/1912.04573" href="https://arxiv.org/abs/1912.04573">Classifying, Segmenting, and Tracking Object Instances in Video with Mask Propagation</a>, <br />with Gedas Bertasius. <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_5"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1912.04487" href="https://arxiv.org/abs/1912.04487">Listen to Look: Action Recognition by Previewing Audio</a>, <br />with Ruohan Gao, Tae-Hyun Oh, and Kristen Grauman.<span class="style_3"><br /></span></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1906.03349" href="https://arxiv.org/abs/1906.03349">Correlation Networks for Video Classification</a>, <br />with Heng Wang, Du Tran, and Matt Feiszli.<span class="style_3"><br /></span></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>New paper presented at AISTATS 2020:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/2003.00605" href="https://arxiv.org/abs/2003.00605">Stein Variational Inference for Discrete Distributions</a>, <br />with Jun Han, Fan Ding, Xianglong Liu, Jian Peng, and Qiang Liu.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Two papers presented at NeurIPS 2019:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1906.04016" href="https://arxiv.org/abs/1906.04016">Learning Temporal Pose Estimation from Sparsely-Labeled Videos</a>, <br />with Gedas Bertasius, Christoph Feichtenhofer, Du Tran, Jianbo Shi.<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://papers.nips.cc/paper/9110-star-caps-capsule-networks-with-straight-through-attentive-routing" href="https://papers.nips.cc/paper/9110-star-caps-capsule-networks-with-straight-through-attentive-routing">STAR-Caps: Capsule Networks with Straight-Through Attentive Routing,</a> <br />with Karim Ahmed.<span class="style_3"><br /></span></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Four papers presented at ICCV 2019:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><span class="style_1">Oral presentation</span>:<br /><a title="https://kor.bar/scsampler/" href="https://kor.bar/scsampler/">SCSampler: Sampling Salient Clips from Video for Efficient Action Recognition</a>, <br />with Bruno Korbar, and Du Tran. <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1904.02811" href="https://arxiv.org/abs/1904.02811">Video Classification with Channel-Separated Convolutional Networks</a>, <br />with Du Tran, Heng Wang, and Matt Feiszli.<span class="style_3"><br /></span></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1901.09244" href="https://arxiv.org/abs/1901.09244">DistInit: Learning Video Representations without a Single Labeled Video</a>, <br />with Rohit Girdhar, Du Tran, and Deva Ramanan.<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/1712.09374" href="https://arxiv.org/abs/1712.09374">HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization</a><span class="style_3">, <br />with Hang Zhao, Zhicheng Yan, and Antonio Torralba.</span><br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_6"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>I co-organized a tutorial at ICCV 2019:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span>Tutorial on <a title="https://sites.google.com/view/learning-with-limited-data" href="https://sites.google.com/view/learning-with-limited-data">Visual Learning with Limited Labeled Data</a><br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_6"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>I co-organized a tutorial and a workshop at CVPR 2019:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span>Tutorial on <a title="https://actionclassification-videomodelling.github.io/" href="https://actionclassification-videomodelling.github.io/">Action Classification and Video Modeling</a><br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span>Workshop on <a title="https://www.cv4gc.org/" href="https://www.cv4gc.org/">Computer Vision for Global Challenges</a><br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>We released a new dataset for action recognition and temporal localization, named <a title="http://hacs.csail.mit.edu/" href="http://hacs.csail.mit.edu/">HACS</a>. It includes over 1.5M video clips. Give it a try!<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>New paper presented at NIPS 2018:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="http://vlg.cs.dartmouth.edu/projects/avts/" href="http://vlg.cs.dartmouth.edu/projects/avts/" class="style_3">Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization</a><span class="style_3">, <br />with Bruno Korbar, and Du Tran.</span><br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Three papers presented at ECCV 2018:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1803.05549" href="https://arxiv.org/abs/1803.05549" class="style_3">Object Detection in Video with Spatiotemporal Sampling Networks</a><span class="style_3">, <br />with Gedas Bertasius, and Jianbo Shi.</span><br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1807.11473" href="https://arxiv.org/abs/1807.11473">MaskConnect: Connectivity Learning by Gradient Descent</a><span class="style_3">, <br />with Karim Ahmed.<br /></span></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span>Scenes-Objects-Actions: A Multi-Task, Multi-Label Video Dataset,<br /><span class="style_3">with </span>Jamie Ray, Heng Wang, Du Tran, Yufei Wang, Matt Feiszli, and Manohar Paluri.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>New paper presented at BMVC 2018:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="http://bmvc2018.org/contents/papers/0345.pdf" href="http://bmvc2018.org/contents/papers/0345.pdf">Self-Supervised Feature Learning for Semantic Segmentation of Overhead Imagery</a><span class="style_3">, <br />with Suriya Singh, Anil Batra, Guan Pang, Saikat Basu, Manohar Paluri, and C.V. Jawahar.<br /></span></p>
                  </li>
                </ol>
                <p class="paragraph_style_6"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Three papers on video models presented at CVPR 2018:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1711.11248" href="https://arxiv.org/abs/1711.11248">A Closer Look at Spatiotemporal Convolutions for Action Recognition</a>, <br />with Du Tran, Heng Wang, Jamie Ray, Yann LeCun, and Manohar Paluri.<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/1712.09184" href="https://arxiv.org/abs/1712.09184">Detect-and-Track: Efficient Pose Estimation in Videos</a>, <br />with Rohit Girdhar, Georgia Gkioxari, Manohar Paluri, and Du Tran.<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="http://www.cs.dartmouth.edu/~lorenzo/Papers/HuangEtAl-cvpr18.pdf" href="http://www.cs.dartmouth.edu/~lorenzo/Papers/HuangEtAl-cvpr18.pdf">What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets</a>,<br />with De-An Huang, Vignesh Ramanathan, Dhruv Mahajan, Juan Carlos Niebles, <br />Fei-Fei  Li, and Manohar Paluri.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_6"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Together with collaborators, I organized two workshops at CVPR 2018:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://bivu2018.github.io" href="https://bivu2018.github.io">Brave New Ideas for Video Understanding</a><br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="http://deepglobe.org/index.html" href="http://deepglobe.org/index.html">DeepGlobe: A Challenge for Parsing the Earth through Satellite Images</a><br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_6"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>From January 2018 to May 2018 I was a Fulbright U.S. Scholar at <a title="http://www.ashesi.edu.gh" href="http://www.ashesi.edu.gh">Ashesi University</a> in Ghana.<br /></p>
                  </li>
                </ol>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style">research overview<br /></p>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style_8">My research interests are in computer vision and machine learning. My current work is primarily focused on learning representations for image and video recognition. You can read more about the research of my group <a title="http://vlg.cs.dartmouth.edu/vlg.html" href="http://vlg.cs.dartmouth.edu/vlg.html">here</a>.<br /></p>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style">previous affiliations<br /></p>
                <p class="paragraph_style_8"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://research.microsoft.com/mlp/" href="http://research.microsoft.com/mlp/">Microsoft Research Cambridge, Machine Learning and Perception</a><br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.riya.com/" href="http://www.riya.com/">Riya</a>/<a title="http://www.like.com/" href="http://www.like.com/">Like.com</a><br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.cs.nyu.edu/" href="http://www.cs.nyu.edu/">New York University, Computer Science</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.cs.stanford.edu/" href="http://www.cs.stanford.edu/">Stanford University, Computer Science</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.digitalpersona.com/" href="http://www.digitalpersona.com/">DigitalPersona</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.itc.it/IRST/en-index.htm" href="http://www.itc.it/IRST/en-index.htm">IRST</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="padding-bottom: 0pt; text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.dsi.unimi.it/index.php?lang=1;z=0" href="http://www.dsi.unimi.it/index.php?lang=1;z=0">University of Milan, Computer Science</a> </p>
                  </li>
                </ol>
              </div>
            </div>
          </div>
          


          <div id="id2" style="height: 302px; left: 314px; position: absolute; top: 7px; width: 377px; z-index: 1; " class="style_SkipStroke_1 shape-with-text">
            <div class="text-content style_External_377_302" style="padding: 0px; ">
              <div class="style">
                <p style="padding-top: 0pt; " class="paragraph_style_10">Lorenzo Torresani<br /></p>
                <p class="paragraph_style_6"><br /></p>
                <p class="paragraph_style_11">Professor of Computer Science<br /></p>
                <p class="paragraph_style_11"><a title="http://vlg.cs.dartmouth.edu/" href="http://vlg.cs.dartmouth.edu/">Visual Learning Group</a><br /></p>
                <p class="paragraph_style_11">Dartmouth College<br /></p>
                <p class="paragraph_style_11"><br /></p>
                <p class="paragraph_style_11">Research Scientist<br /></p>
                <p class="paragraph_style_11">Facebook AI <br /></p>
                <p class="paragraph_style_11"><br /></p>
                <p style="padding-bottom: 0pt; " class="paragraph_style_11">Email: <a title="mailto:LT@dartmouth.edu" href="mailto:LT@dartmouth.edu">LT@dartmouth.edu</a></p>
              </div>
            </div>
          </div>
          <div style="height: 2818px; line-height: 2818px; " class="spacer"> </div>
        </div>
        <div style="height: 75px; margin-left: 0px; position: relative; width: 700px; z-index: 15; " id="footer_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
        </div>
      </div>
    </div>
  </body>
</html>


