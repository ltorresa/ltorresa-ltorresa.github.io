<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="Generator" content="iWeb 3.0.4" />
    <meta name="iWeb-Build" content="local-build-20201003" />
    <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7" />
    <meta name="viewport" content="width=700" />
    <title>home</title>
    <link rel="stylesheet" type="text/css" media="screen,print" href="home_files/home.css" />
    <!--[if lt IE 8]><link rel='stylesheet' type='text/css' media='screen,print' href='home_files/homeIE.css'/><![endif]-->
    <!--[if gte IE 8]><link rel='stylesheet' type='text/css' media='screen,print' href='Media/IE8.css'/><![endif]-->
    <script type="text/javascript" src="Scripts/iWebSite.js"></script>
    <script type="text/javascript" src="Scripts/Widgets/SharedResources/WidgetCommon.js"></script>
    <script type="text/javascript" src="Scripts/Widgets/Navbar/navbar.js"></script>
    <script type="text/javascript" src="Scripts/iWebImage.js"></script>
    <script type="text/javascript" src="home_files/home.js"></script>
  </head>
  <body style="background: rgb(255, 255, 255); margin: 0pt; " onload="onPageLoad();" onunload="onPageUnload();">
    <div style="text-align: center; ">
      <div style="margin-bottom: 10px; margin-left: auto; margin-right: auto; margin-top: 10px; overflow: hidden; position: relative; word-wrap: break-word;  background: rgb(255, 255, 255); text-align: left; width: 700px; " id="body_content">
        <div style="margin-left: 0px; position: relative; width: 700px; z-index: 0; " id="nav_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
          <div class="com-apple-iweb-widget-navbar flowDefining" id="widget0" style="margin-left: 20px; margin-top: 0px; opacity: 1.00; position: relative; width: 680px; z-index: 1; ">
    
            <div id="widget0-navbar" class="navbar">

      
              <div id="widget0-bg" class="navbar-bg">

        
                <ul id="widget0-navbar-list" class="navbar-list">
 <li></li> 
</ul>
                
      
</div>
              
    
</div>
          </div>
          <script type="text/javascript"><!--//--><![CDATA[//><!--
new NavBar('widget0', 'Scripts/Widgets/Navbar', 'Scripts/Widgets/SharedResources', '.', {"path-to-root": "", "navbar-css": ".navbar {\n\tfont-family: 'Helvetica Neue', Arial, sans-serif;\n\tfont-size: .8em;\n\tcolor: #666666;\n\tline-height: 30px;\n\tborder-bottom: 3px solid #ccc;\n}\n\n.navbar-bg {\n\ttext-align: right;}\n\n.navbar-bg ul {\n\tlist-style: none;\n\tmargin: 0px;\n\tpadding: 0px;\n}\n\n\nli {\n\tlist-style-type: none;\n\tdisplay: inline;\n\tpadding: 0px 5px 0px 0px;\n}\n\n\nli a {\n\ttext-decoration: none;\n\tpadding: 10px;\n\tcolor: #666666;\n\tfont-weight: bold;\n}\n\nli a:visited {\n\ttext-decoration: none;\n\tpadding: 10px;\n\tcolor: #666666;\n\tfont-weight: bold;\n}\n\nli a:hover\r{\r\n \tcolor: #999999;\n\ttext-decoration: none;\r}\n\n\nli.current-page a\r{\r\t color: #66ABC5;\n\ttext-decoration: none;\r}", "current-page-GUID": "53243ACB-6697-4184-B8D3-F5B11E08E9D2", "isCollectionPage": "NO"});
//--><!]]></script>
          <div style="clear: both; height: 0px; line-height: 0px; " class="spacer"> </div>
        </div>
        <div style="height: 75px; margin-left: 0px; position: relative; width: 700px; z-index: 10; " id="header_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
        </div>
        <div style="margin-left: 0px; position: relative; width: 700px; z-index: 5; " id="body_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
          <div style="height: 281px; width: 251px;  height: 281px; left: 34px; position: absolute; top: 22px; width: 251px; z-index: 1; " class="tinyText style_SkipStroke stroke_0">
            <img src="home_files/LT.jpg" alt="" style="border: none; height: 281px; width: 251px; " />
          </div>
          


          <div id="id1" style="height: 2476px; left: 41px; position: absolute; top: 342px; width: 613px; z-index: 1; " class="style_SkipStroke_1 shape-with-text">
            <div class="text-content style_External_613_2476" style="padding: 0px; ">
              <div class="style">
                <p style="padding-top: 0pt; " class="paragraph_style">recent news<br /></p>

                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Four new papers to be presented at CVPR 2022:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2201.10990" href="https://arxiv.org/abs/2201.10990">Learning To Recognize Procedural Activities with Distant Supervision</a>, <br />with Xudong Lin, Fabio Petroni, Gedas Bertasius, Marcus Rohrbach, and Shih-Fu Chang. <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2203.16795" href="https://arxiv.org/abs/2203.16795">Deformable Video Transformer</a>,<br />with Jue Wang.<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2106.09212" href="https://arxiv.org/abs/2106.09212">Long-Short Temporal Contrastive Learning of Video Transformers</a>,<br />with Jue Wang.<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2110.07058" href="https://arxiv.org/abs/2110.07058">Ego4D: Around the World in 3,000 Hours of Egocentric Video</a>.<br />Project page and dataset available <a title="https://ego4d-data.org/" href="https://ego4d-data.org/">here</a>.<br /></p>
                  </li>                  
                </ol>

                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>New paper presented at AAAI 2022:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://arxiv.org/abs/2112.03340" href="https://arxiv.org/abs/2112.03340">Label Hallucination for Few-Shot Classification</a>, <br />with Yiren Jian.<br /></p>
                  </li>
                </ol>

                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>New article published in IEEE Transactions on Pattern Analysis and Machine Intelligence:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_4"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 3px; " class="inline-block"></span><a title="https://doi.ieeecomputersociety.org/10.1109/TPAMI.2021.3120550" href="https://doi.ieeecomputersociety.org/10.1109/TPAMI.2021.3120550">Generalized Few-Shot Video Classification with Video Retrieval and Feature Generation</a>, <br />with Yongqin Xian, Bruno Korbar, Matthijs Douze, Bernt Schiele, and Zeynep Akata.<br /></p>
                  </li>
                </ol>
                
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>I gave three keynotes at CVPR 2021 workshops:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span>"Video Understanding with Language Models," <a title="https://eyewear-computing.org/EPIC_CVPR21/" href="https://eyewear-computing.org/EPIC_CVPR21/">EPIC@CVPR2021</a>, The Eight International Workshop on Egocentric
                    Perception, Interaction and Computing.<br/>[<a title="https://youtu.be/UNOjaahJ_E0" href="https://youtu.be/UNOjaahJ_E0">video link</a>]<br/></p>
                  </li>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span>"Vision using Sight... but also Sound and Speech," <a title="https://mula-workshop.github.io/" href="https://mula-workshop.github.io/">MULA</a>, The Fourth Multimodal Learning and Applications Workshop. [<a title="https://dartmouth.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=13e99fc6-a1a5-43af-8e28-ad49012c0efd" href="https://dartmouth.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=13e99fc6-a1a5-43af-8e28-ad49012c0efd">video link</a>]<br/></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span>"Space-Time Models for Segmentation, Tracking and Recognition in Video," <a title="https://eval.vision.rwth-aachen.de/rvsu-workshop21/" href="https://eval.vision.rwth-aachen.de/rvsu-workshop21/">RVSU</a>, Robust Video Scene Understanding Workshop. [<a title="https://youtu.be/bwIgpxmWnWM?t=6064" href="https://youtu.be/bwIgpxmWnWM?t=6064">video link</a>]<br/></p>
                  </li>
                  
                </ol>

                
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>A Facebook AI <a title="https://ai.facebook.com/blog/timesformer-a-new-architecture-for-video-understanding/" href="https://ai.facebook.com/blog/timesformer-a-new-architecture-for-video-understanding/">blog article</a> describing our new research on video understanding. Code and pretrained models are available <a title="https://github.com/facebookresearch/TimeSformer" href="https://github.com/facebookresearch/TimeSformer">here</a>.<br /></p>
                  </li>
                </ol>                

                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Two new papers to be presented at ICML 2021:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2102.05095" href="https://arxiv.org/abs/2102.05095">Is Space-Time Attention All You Need for Video Understanding?</a>, <br />with Gedas Bertasius, and Heng Wang. <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2101.06475" href="https://arxiv.org/abs/2101.06475">Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks
</a>,<br />with Maxwell Aladago.<br /></p>
                  </li>
                </ol>
                
                <p class="paragraph_style_1"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_2"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 11px; " class="inline-block"></span>Two new papers presented at CVPR 2021:<br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2101.12059" href="https://arxiv.org/abs/2101.12059">VX2TEXT: End-to-End Learning of Video-Based Text Generation From Multimodal Inputs</a>, <br />with Xudong Lin, Gedas Bertasius, Jue Wang, Shih-Fu Chang, and Devi Parikh. <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 34px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_3"><span style="font-family: '.SFNSText', '.SF NS Text'; font-size: 15px; font-stretch: normal; font-style: normal; font-weight: 400; position: relative; top: 1px; " class="Bullet">✓</span><span style="width: 4px; " class="inline-block"></span><a title="https://arxiv.org/abs/2104.01198" href="https://arxiv.org/abs/2104.01198">Beyond Short Clips: End-to-End Video-Level Learning with Collaborative Memories</a>,<br />with Xitong Yang, Haoqi Fan, Larry Davis, and Heng Wang.<br /></p>
                  </li>
                </ol>

                <p class="paragraph_style_6"><br /></p>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style">research overview<br /></p>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style_8">My research interests are in computer vision and machine learning. My current work is primarily focused on learning representations for image and video understanding.<br /></p>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style_7"><br /></p>
                <p class="paragraph_style">previous affiliations<br /></p>
                <p class="paragraph_style_8"><br /></p>
                <ol>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="https://web.cs.dartmouth.edu/" href="https://web.cs.dartmouth.edu/">Dartmouth, Computer Science</a> <br /></p>
                  </li>                
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">                  
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span>Fulbright U.S. Scholar at <a title="http://www.ashesi.edu.gh" href="http://www.ashesi.edu.gh">Ashesi University</a> in Ghana.<br /></p>
                  </li>
                  
                   <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://research.microsoft.com/mlp/" href="http://research.microsoft.com/mlp/">Microsoft Research Cambridge, Machine Learning and Perception</a><br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.riya.com/" href="http://www.riya.com/">Riya</a>/<a title="http://www.like.com/" href="http://www.like.com/">Like.com</a><br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.cs.nyu.edu/" href="http://www.cs.nyu.edu/">New York University, Computer Science</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.cs.stanford.edu/" href="http://www.cs.stanford.edu/">Stanford University, Computer Science</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.digitalpersona.com/" href="http://www.digitalpersona.com/">DigitalPersona</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.itc.it/IRST/en-index.htm" href="http://www.itc.it/IRST/en-index.htm">IRST</a> <br /></p>
                  </li>
                  <li style="line-height: 20px; padding-left: 17px; text-indent: -17px; " class="full-width">
                    <p style="padding-bottom: 0pt; text-indent: -17px; " class="paragraph_style_9"><span style="font-size: 15px; " class="Bullet">•</span><span style="width: 12px; " class="inline-block"></span><a title="http://www.dsi.unimi.it/index.php?lang=1;z=0" href="http://www.dsi.unimi.it/index.php?lang=1;z=0">University of Milan, Computer Science</a> </p>
                  </li>
                </ol>
              </div>
            </div>
          </div>
          


          <div id="id2" style="height: 302px; left: 314px; position: absolute; top: 7px; width: 377px; z-index: 1; " class="style_SkipStroke_1 shape-with-text">
            <div class="text-content style_External_377_302" style="padding: 0px; ">
              <div class="style">
                <p style="padding-top: 0pt; " class="paragraph_style_10">Lorenzo Torresani<br /></p>
                <p class="paragraph_style_11"><br /></p>
                <p class="paragraph_style_11">Research Lead<br /></p>
                <p class="paragraph_style_11">Facebook AI Research (FAIR), Meta<br /></p>
                <p class="paragraph_style_11"><br /></p>
                <p style="padding-bottom: 0pt; " class="paragraph_style_11"><a title="mailto:torresani@gmail.com" href="mailto:torresani@gmail.com">Email</a>  / 
<a title="https://scholar.google.com/citations?user=ss8KR5gAAAAJ&hl=en&pagesize=1000&sortby=pubdate" href="https://scholar.google.com/citations?user=ss8KR5gAAAAJ&hl=en&pagesize=1000&sortby=pubdate">Google Scholar</a></p>

              </div>
            </div>
          </div>
          <div style="height: 2318px; line-height: 2318px; " class="spacer"> </div>
        </div>
        <div style="height: 75px; margin-left: 0px; position: relative; width: 700px; z-index: 15; " id="footer_layer">
          <div style="height: 0px; line-height: 0px; " class="bumper"> </div>
        </div>
      </div>
    </div>
  </body>
</html>


